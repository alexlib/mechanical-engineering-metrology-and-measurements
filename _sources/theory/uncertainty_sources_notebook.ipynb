{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-title",
   "metadata": {},
   "source": [
    "# Sources of Uncertainty in Measurement for Every Uncertainty Budget\n",
    "\n",
    "**Based on the guide by Rick Hogan, ISOBudgets LLC (2015)**\n",
    "\n",
    "This notebook demonstrates the 8 essential sources of uncertainty that should be included in every uncertainty budget, with practical calculations and examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-intro",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**The 8 Sources of Uncertainty in Measurement that should be included in every uncertainty budget:**\n",
    "\n",
    "1. **Repeatability**\n",
    "2. **Reproducibility** \n",
    "3. **Stability**\n",
    "4. **Bias**\n",
    "5. **Drift**\n",
    "6. **Resolution**\n",
    "7. **Reference Standard**\n",
    "8. **Reference Standard Stability**\n",
    "\n",
    "These uncertainty sources typically influence every measurement you will ever make and are commonly required by accreditation bodies like A2LA.\n",
    "\n",
    "### 6 Common Categories of Uncertainty Sources:\n",
    "- Equipment\n",
    "- Unit Under Test\n",
    "- Operator\n",
    "- Method\n",
    "- Calibration\n",
    "- Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 Sources of Uncertainty Analysis - Setup Complete\n",
      "Based on Rick Hogan's ISOBudgets Guide (2015)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"8 Sources of Uncertainty Analysis - Setup Complete\")\n",
    "print(\"Based on Rick Hogan's ISOBudgets Guide (2015)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-repeatability-theory",
   "metadata": {},
   "source": [
    "## 1. Repeatability\n",
    "\n",
    "**Definition:** Measurement precision under a set of repeatability conditions of measurement.\n",
    "\n",
    "Repeatability is the measurement precision under a set of repeatable conditions. It represents **Type A uncertainty** and captures random variations in your measurement process.\n",
    "\n",
    "**Formula:**\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\bar{y})^2}$$\n",
    "\n",
    "**How to Calculate:**\n",
    "1. Repeat a measurement 'n' number of times\n",
    "2. Record the results of each measurement\n",
    "3. Calculate the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-repeatability-calc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. REPEATABILITY CALCULATION\n",
      "========================================\n",
      "Number of samples: 20\n",
      "Measurements (ppm): [12.48  9.31 13.24 17.62  8.83  8.83 17.9  13.84  7.65 12.71  7.68  7.67\n",
      " 11.21  0.43  1.38  7.19  4.94 11.57  5.46  2.94]\n",
      "Mean: 9.14 ppm\n",
      "Repeatability (σ): 4.8 ppm\n",
      "Degrees of freedom: 19\n",
      "\n",
      "Excel formula equivalent: =STDEV(A1:A20)\n"
     ]
    }
   ],
   "source": [
    "# Repeatability Example - Simulating 20 samples as in the original document\n",
    "# Nominal value = 10, standard deviation = 5 ppm\n",
    "\n",
    "print(\"1. REPEATABILITY CALCULATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Generate 20 normally distributed samples\n",
    "nominal_value = 10.0  # ppm\n",
    "true_std = 5.0  # ppm\n",
    "n_samples = 20\n",
    "\n",
    "# Simulate measurements\n",
    "measurements = np.random.normal(nominal_value, true_std, n_samples)\n",
    "\n",
    "# Calculate repeatability (standard deviation)\n",
    "repeatability = np.std(measurements, ddof=1)  # Sample standard deviation\n",
    "degrees_of_freedom = n_samples - 1\n",
    "\n",
    "print(f\"Number of samples: {n_samples}\")\n",
    "print(f\"Measurements (ppm): {measurements.round(2)}\")\n",
    "print(f\"Mean: {np.mean(measurements):.2f} ppm\")\n",
    "print(f\"Repeatability (σ): {repeatability:.1f} ppm\")\n",
    "print(f\"Degrees of freedom: {degrees_of_freedom}\")\n",
    "\n",
    "# Store for later use\n",
    "uncertainty_budget = {'Repeatability': repeatability}\n",
    "\n",
    "print(f\"\\nExcel formula equivalent: =STDEV(A1:A{n_samples})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-reproducibility-theory",
   "metadata": {},
   "source": [
    "## 2. Reproducibility\n",
    "\n",
    "**Definition:** Measurement precision under reproducibility conditions of measurement.\n",
    "\n",
    "Reproducibility differs from repeatability because you need to **change a variable** in your measurement process.\n",
    "\n",
    "**5 Most Common Comparisons for Reproducibility Testing:**\n",
    "- Operator vs Operator\n",
    "- Equipment vs Equipment  \n",
    "- Method vs Method\n",
    "- Day vs Day\n",
    "- Environment vs Environment\n",
    "\n",
    "**How to Calculate:**\n",
    "1. Perform a Repeatability Test\n",
    "2. Calculate the mean or average\n",
    "3. Change a variable and repeat the Repeatability Test\n",
    "4. Calculate the mean or average\n",
    "5. Calculate the standard deviation of the test averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-reproducibility-calc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. REPRODUCIBILITY CALCULATION\n",
      "========================================\n",
      "Method 1 - Mean: 8.67 ppm\n",
      "Method 2 - Mean: 9.87 ppm\n",
      "\n",
      "Means array: [8.67 9.87]\n",
      "Reproducibility (σ): 0.8 ppm\n",
      "Degrees of freedom: 1\n",
      "\n",
      "Excel formula equivalent: =STDEV(8.67,9.87)\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility Example - Method vs Method comparison\n",
    "print(\"2. REPRODUCIBILITY CALCULATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Simulate two different methods with 20 samples each\n",
    "method1_samples = np.random.normal(nominal_value, true_std, n_samples)\n",
    "method2_samples = np.random.normal(nominal_value, true_std, n_samples)\n",
    "\n",
    "# Calculate means for each method\n",
    "mean1 = np.mean(method1_samples)\n",
    "mean2 = np.mean(method2_samples)\n",
    "\n",
    "print(f\"Method 1 - Mean: {mean1:.2f} ppm\")\n",
    "print(f\"Method 2 - Mean: {mean2:.2f} ppm\")\n",
    "\n",
    "# Calculate reproducibility (standard deviation of means)\n",
    "means_array = np.array([mean1, mean2])\n",
    "reproducibility = np.std(means_array, ddof=1)\n",
    "reprod_dof = len(means_array) - 1\n",
    "\n",
    "print(f\"\\nMeans array: {means_array.round(2)}\")\n",
    "print(f\"Reproducibility (σ): {reproducibility:.1f} ppm\")\n",
    "print(f\"Degrees of freedom: {reprod_dof}\")\n",
    "\n",
    "uncertainty_budget['Reproducibility'] = reproducibility\n",
    "\n",
    "print(f\"\\nExcel formula equivalent: =STDEV({mean1:.2f},{mean2:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-stability-theory",
   "metadata": {},
   "source": [
    "## 3. Stability\n",
    "\n",
    "**Definition:** Property of a measuring instrument, whereby its metrological properties remain constant in time.\n",
    "\n",
    "Stability is a **random uncertainty** that determines how stable your measurement process is over time. It's commonly confused with Drift (which is systematic).\n",
    "\n",
    "**How to Calculate:**\n",
    "1. Review your last 3 calibration reports\n",
    "2. Record the results from each calibration report\n",
    "3. Calculate the standard deviation of the calibration results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-stability-calc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. STABILITY CALCULATION\n",
      "========================================\n",
      "Calibration results over time:\n",
      "2013: 12.5 ppm\n",
      "2014: 8.7 ppm\n",
      "2015: 6.3 ppm\n",
      "\n",
      "Stability (σ): 3.1 ppm\n",
      "Degrees of freedom: 2\n",
      "\n",
      "Excel formula equivalent: =STDEV(12.5,8.7,6.3)\n"
     ]
    }
   ],
   "source": [
    "# Stability Example - Using calibration data from Keysight 34401A (10V DC)\n",
    "print(\"3. STABILITY CALCULATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Simulated calibration results from 3 different years (ppm)\n",
    "# Based on actual Keysight 34401A data from the document\n",
    "cal_2013 = 12.5  # ppm\n",
    "cal_2014 = 8.7   # ppm \n",
    "cal_2015 = 6.3   # ppm\n",
    "\n",
    "calibration_results = np.array([cal_2013, cal_2014, cal_2015])\n",
    "\n",
    "print(f\"Calibration results over time:\")\n",
    "print(f\"2013: {cal_2013} ppm\")\n",
    "print(f\"2014: {cal_2014} ppm\")\n",
    "print(f\"2015: {cal_2015} ppm\")\n",
    "\n",
    "# Calculate stability\n",
    "stability = np.std(calibration_results, ddof=1)\n",
    "stability_dof = len(calibration_results) - 1\n",
    "\n",
    "print(f\"\\nStability (σ): {stability:.1f} ppm\")\n",
    "print(f\"Degrees of freedom: {stability_dof}\")\n",
    "\n",
    "uncertainty_budget['Stability'] = stability\n",
    "\n",
    "print(f\"\\nExcel formula equivalent: =STDEV({cal_2013},{cal_2014},{cal_2015})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-bias-theory",
   "metadata": {},
   "source": [
    "## 4. Bias\n",
    "\n",
    "**Definition:** \n",
    "1. Estimate of systematic measurement error\n",
    "2. Average of replicate indication minus a reference quantity value\n",
    "\n",
    "Bias is really a **systematic error** rather than an uncertainty. Whether to include it depends on your measurement process:\n",
    "\n",
    "**Scenario 1:** You calibrate equipment using a known reference standard and report the result only.\n",
    "→ **ADD bias to uncertainty budget**\n",
    "\n",
    "**Scenario 2:** You calibrate equipment and report both Standard value and Unit Under Test value.\n",
    "→ **DO NOT add bias to uncertainty budget**\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "Bias = measured value - standard value  or $b = mv - sv$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-bias-calc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. BIAS CALCULATION\n",
      "========================================\n",
      "Standard value (Fluke 5720A): 10.000000 V\n",
      "Measured value (Keysight 34401A): 10.000073 V\n",
      "\n",
      "Bias: 0.000073 V\n",
      "Bias: 73.0 ppm\n",
      "\n",
      "Note: Include in uncertainty budget only if you report results without\n",
      "accounting for the reference standard bias (Scenario 1)\n",
      "\n",
      "Excel formula equivalent: =10.000073 - 10.000000\n"
     ]
    }
   ],
   "source": [
    "# Bias Example - Fluke 5720A vs Keysight 34401A comparison\n",
    "print(\"4. BIAS CALCULATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Example values from calibration reports\n",
    "standard_value = 10.000000  # V (Fluke 5720A reference)\n",
    "measured_value = 10.000073  # V (Keysight 34401A result)\n",
    "\n",
    "print(f\"Standard value (Fluke 5720A): {standard_value:.6f} V\")\n",
    "print(f\"Measured value (Keysight 34401A): {measured_value:.6f} V\")\n",
    "\n",
    "# Calculate bias\n",
    "bias = measured_value - standard_value\n",
    "bias_ppm = bias * 1e6  # Convert to ppm\n",
    "\n",
    "print(f\"\\nBias: {bias:.6f} V\")\n",
    "print(f\"Bias: {bias_ppm:.1f} ppm\")\n",
    "\n",
    "# Note: Whether to include this in uncertainty budget depends on your process\n",
    "print(f\"\\nNote: Include in uncertainty budget only if you report results without\")\n",
    "print(f\"accounting for the reference standard bias (Scenario 1)\")\n",
    "\n",
    "print(f\"\\nExcel formula equivalent: ={measured_value:.6f} - {standard_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-drift-theory",
   "metadata": {},
   "source": [
    "## 5. Drift\n",
    "\n",
    "**Definition:** Continuous or incremental change over time in indication, due to changes in metrological properties of a measuring instrument.\n",
    "\n",
    "Drift is a **systematic uncertainty** that determines how the error in your measurement process changes over time.\n",
    "\n",
    "**Formula:**\n",
    "$$drift = I \\cdot \\frac{1}{n}\\sum_{i=1}^{n}\\frac{\\delta y}{\\delta t}$$\n",
    "\n",
    "Where I = calibration interval\n",
    "\n",
    "**How to Calculate:**\n",
    "1. Review your last 3 calibration reports\n",
    "2. Record the results and dates from each calibration\n",
    "3. Calculate the average daily drift rate\n",
    "4. Multiply by your calibration interval (in days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-drift-calc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. DRIFT CALCULATION\n",
      "========================================\n",
      "Calibration history:\n",
      "2013-01-15: 12.5 ppm\n",
      "2014-01-15: 8.7 ppm\n",
      "2015-01-15: 6.3 ppm\n",
      "\n",
      "Daily drift rate 2014-2015: -0.006571 ppm/day\n",
      "Daily drift rate 2013-2014: -0.010404 ppm/day\n",
      "Average daily drift rate: -0.008487 ppm/day\n",
      "\n",
      "Annual drift: 3.1 ppm\n",
      "\n",
      "Note: Use absolute value as this represents uncertainty magnitude\n"
     ]
    }
   ],
   "source": [
    "# Drift Example - Using same Keysight 34401A calibration data\n",
    "print(\"5. DRIFT CALCULATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Calibration data with dates\n",
    "cal_data = {\n",
    "    '2013-01-15': 12.5,  # ppm\n",
    "    '2014-01-15': 8.7,   # ppm\n",
    "    '2015-01-15': 6.3    # ppm\n",
    "}\n",
    "\n",
    "dates = list(cal_data.keys())\n",
    "values = list(cal_data.values())\n",
    "\n",
    "print(f\"Calibration history:\")\n",
    "for date, value in cal_data.items():\n",
    "    print(f\"{date}: {value} ppm\")\n",
    "\n",
    "# Calculate daily drift rates\n",
    "# 2014 to 2015 drift rate\n",
    "drift_2014_2015 = (values[2] - values[1]) / 365.25  # per day\n",
    "print(f\"\\nDaily drift rate 2014-2015: {drift_2014_2015:.6f} ppm/day\")\n",
    "\n",
    "# 2013 to 2014 drift rate  \n",
    "drift_2013_2014 = (values[1] - values[0]) / 365.25  # per day\n",
    "print(f\"Daily drift rate 2013-2014: {drift_2013_2014:.6f} ppm/day\")\n",
    "\n",
    "# Average daily drift rate\n",
    "avg_daily_drift = (drift_2014_2015 + drift_2013_2014) / 2\n",
    "print(f\"Average daily drift rate: {avg_daily_drift:.6f} ppm/day\")\n",
    "\n",
    "# Annual drift (365.25 days)\n",
    "annual_drift = abs(avg_daily_drift * 365.25)\n",
    "print(f\"\\nAnnual drift: {annual_drift:.1f} ppm\")\n",
    "\n",
    "uncertainty_budget['Drift'] = annual_drift\n",
    "\n",
    "print(f\"\\nNote: Use absolute value as this represents uncertainty magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-resolution-theory",
   "metadata": {},
   "source": [
    "## 6. Resolution\n",
    "\n",
    "**Definition:** Smallest change in a quantity being measured that causes a perceptible change in the corresponding indication.\n",
    "\n",
    "Resolution must be included in every uncertainty budget. Whether to include UUT resolution depends on your process:\n",
    "\n",
    "**Scenario 1:** Single measurement process or same type of UUT always\n",
    "→ **ADD UUT Resolution to uncertainty budget**\n",
    "\n",
    "**Scenario 2:** Single measurement function where UUT type can vary\n",
    "→ **DO NOT add UUT Resolution** (calculate after each test per ILAC P14)\n",
    "\n",
    "**How to Find Resolution:**\n",
    "1. Look at your measurement system or equipment\n",
    "2. Find the least significant digit\n",
    "3. Observe the smallest incremental change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-resolution-calc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. RESOLUTION EXAMPLES\n",
      "========================================\n",
      "Digital Multimeter Resolution:\n",
      "Display: 10.000000 V\n",
      "Resolution: 1e-05 V = 10 μV\n",
      "\n",
      "Resolution uncertainty:\n",
      "Formula: u = resolution / (2√3)\n",
      "u = 1e-05 / (2√3) = 2.89e-06 V\n",
      "u = 0.29 ppm (at 10V)\n",
      "\n",
      "------------------------------\n",
      "Other Device Types:\n",
      "• Analog scales: Consider marker spacing, width, pointer width\n",
      "• Artifacts: Use least significant digit from calibration reports\n",
      "• Digital devices: Observe least significant digit changes\n"
     ]
    }
   ],
   "source": [
    "# Resolution Examples for Different Device Types\n",
    "print(\"6. RESOLUTION EXAMPLES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Digital Multimeter Example (from document)\n",
    "print(\"Digital Multimeter Resolution:\")\n",
    "dmm_display = \"10.000000 V\"  # 6 decimal places\n",
    "dmm_resolution = 0.000010  # 10 microvolts\n",
    "print(f\"Display: {dmm_display}\")\n",
    "print(f\"Resolution: {dmm_resolution} V = {dmm_resolution*1e6:.0f} μV\")\n",
    "\n",
    "# Calculate resolution uncertainty (rectangular distribution)\n",
    "# For digital instruments: u = resolution / (2 * sqrt(3))\n",
    "resolution_uncertainty_V = dmm_resolution / (2 * math.sqrt(3))\n",
    "resolution_uncertainty_ppm = (resolution_uncertainty_V / 10.0) * 1e6\n",
    "\n",
    "print(f\"\\nResolution uncertainty:\")\n",
    "print(f\"Formula: u = resolution / (2√3)\")\n",
    "print(f\"u = {dmm_resolution} / (2√3) = {resolution_uncertainty_V:.2e} V\")\n",
    "print(f\"u = {resolution_uncertainty_ppm:.2f} ppm (at 10V)\")\n",
    "\n",
    "uncertainty_budget['Resolution'] = resolution_uncertainty_ppm\n",
    "\n",
    "# Other device types\n",
    "print(f\"\\n\" + \"-\"*30)\n",
    "print(\"Other Device Types:\")\n",
    "print(\"• Analog scales: Consider marker spacing, width, pointer width\")\n",
    "print(\"• Artifacts: Use least significant digit from calibration reports\")\n",
    "print(\"• Digital devices: Observe least significant digit changes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-ref-std-theory",
   "metadata": {},
   "source": [
    "## 7. Reference Standard Uncertainty\n",
    "\n",
    "**Definition:** Uncertainty of a measurement standard designated for the calibration of other measurement standards for quantities of a given kind in a given organization or at a given location.\n",
    "\n",
    "Reference standard uncertainty is a **systematic uncertainty** introduced from equipment calibration. It's traceable to national/international standards.\n",
    "\n",
    "**Critical Note:** More laboratories get deficiencies for leaving reference standard uncertainty out of their uncertainty budget than any other source.\n",
    "\n",
    "**How to Find:**\n",
    "1. Review your latest calibration report\n",
    "2. Find the reported estimate of measurement uncertainty\n",
    "3. This is your reference standard uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-ref-std-calc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. REFERENCE STANDARD UNCERTAINTY\n",
      "========================================\n",
      "From calibration report (10 VDC measurement):\n",
      "Reference Standard Uncertainty: 2.1 ppm\n",
      "\n",
      "Expert Tips:\n",
      "• Option 1: Use most recent reported uncertainty value\n",
      "• Option 2: Average last 3 uncertainty values\n",
      "• Choose method that gives lowest uncertainty if seeking to minimize\n",
      "• Always use ISO/IEC 17025 accredited calibration reports\n",
      "\n",
      "Example with multiple calibrations:\n",
      "Last 3 reported uncertainties: [2.3, 2.1, 1.9] ppm\n",
      "Average: 2.1 ppm\n",
      "Most recent: 1.9 ppm\n",
      "Choose: 1.9 ppm (lowest)\n"
     ]
    }
   ],
   "source": [
    "# Reference Standard Uncertainty Example\n",
    "print(\"7. REFERENCE STANDARD UNCERTAINTY\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Example from Keysight 34401A calibration report at 10 VDC\n",
    "ref_std_uncertainty_ppm = 2.1  # ppm (from calibration report)\n",
    "\n",
    "print(f\"From calibration report (10 VDC measurement):\")\n",
    "print(f\"Reference Standard Uncertainty: {ref_std_uncertainty_ppm} ppm\")\n",
    "\n",
    "uncertainty_budget['Reference Standard'] = ref_std_uncertainty_ppm\n",
    "\n",
    "print(f\"\\nExpert Tips:\")\n",
    "print(f\"• Option 1: Use most recent reported uncertainty value\")\n",
    "print(f\"• Option 2: Average last 3 uncertainty values\")\n",
    "print(f\"• Choose method that gives lowest uncertainty if seeking to minimize\")\n",
    "print(f\"• Always use ISO/IEC 17025 accredited calibration reports\")\n",
    "\n",
    "# Show multiple calibration example\n",
    "cal_uncertainties = [2.3, 2.1, 1.9]  # ppm from last 3 calibrations\n",
    "avg_uncertainty = np.mean(cal_uncertainties)\n",
    "\n",
    "print(f\"\\nExample with multiple calibrations:\")\n",
    "print(f\"Last 3 reported uncertainties: {cal_uncertainties} ppm\")\n",
    "print(f\"Average: {avg_uncertainty:.1f} ppm\")\n",
    "print(f\"Most recent: {cal_uncertainties[-1]} ppm\")\n",
    "print(f\"Choose: {min(avg_uncertainty, cal_uncertainties[-1]):.1f} ppm (lowest)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-ref-std-stab-theory",
   "metadata": {},
   "source": [
    "## 8. Reference Standard Stability\n",
    "\n",
    "**Definition:** Stability of a measurement standard designated for the calibration of other measurement standards.\n",
    "\n",
    "Reference standard stability is a **random uncertainty** that evaluates the stability of your traceable uncertainty over time.\n",
    "\n",
    "**Two Relevant Scenarios:**\n",
    "\n",
    "**Scenario 1:** Same laboratory calibrates your equipment, but reported uncertainty changes each time\n",
    "→ Determines stability of calibration lab's reference standard\n",
    "\n",
    "**Scenario 2:** Different laboratories calibrate your equipment with different reported uncertainties\n",
    "→ Determines stability of your traceable uncertainty\n",
    "\n",
    "**How to Calculate:**\n",
    "1. Review your last 3 calibration reports\n",
    "2. Record the uncertainty estimate from each report\n",
    "3. Calculate the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-ref-std-stab-calc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8. REFERENCE STANDARD STABILITY\n",
      "========================================\n",
      "Reported uncertainties from calibration reports:\n",
      "2013: 2.3 ppm\n",
      "2014: 2.1 ppm\n",
      "2015: 1.9 ppm\n",
      "\n",
      "Reference Standard Stability: 0.20 ppm\n",
      "Degrees of freedom: 2\n",
      "\n",
      "Excel formula equivalent: =STDEV(2.3,2.1,1.9)\n",
      "\n",
      "Interpretation:\n",
      "• Variability in reported calibration uncertainties over time\n",
      "• Indicates stability of calibration laboratory's measurement capability\n",
      "• Important for laboratories using multiple calibration providers\n"
     ]
    }
   ],
   "source": [
    "# Reference Standard Stability Example\n",
    "print(\"8. REFERENCE STANDARD STABILITY\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Uncertainty values from last 3 calibration reports (ppm)\n",
    "uncertainty_2013 = 2.3  # ppm\n",
    "uncertainty_2014 = 2.1  # ppm  \n",
    "uncertainty_2015 = 1.9  # ppm\n",
    "\n",
    "uncertainty_values = np.array([uncertainty_2013, uncertainty_2014, uncertainty_2015])\n",
    "\n",
    "print(f\"Reported uncertainties from calibration reports:\")\n",
    "print(f\"2013: {uncertainty_2013} ppm\")\n",
    "print(f\"2014: {uncertainty_2014} ppm\")\n",
    "print(f\"2015: {uncertainty_2015} ppm\")\n",
    "\n",
    "# Calculate reference standard stability\n",
    "ref_std_stability = np.std(uncertainty_values, ddof=1)\n",
    "ref_std_stab_dof = len(uncertainty_values) - 1\n",
    "\n",
    "print(f\"\\nReference Standard Stability: {ref_std_stability:.2f} ppm\")\n",
    "print(f\"Degrees of freedom: {ref_std_stab_dof}\")\n",
    "\n",
    "uncertainty_budget['Ref Std Stability'] = ref_std_stability\n",
    "\n",
    "print(f\"\\nExcel formula equivalent: =STDEV({uncertainty_2013},{uncertainty_2014},{uncertainty_2015})\")\n",
    "\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"• Variability in reported calibration uncertainties over time\")\n",
    "print(f\"• Indicates stability of calibration laboratory's measurement capability\")\n",
    "print(f\"• Important for laboratories using multiple calibration providers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-budget-summary",
   "metadata": {},
   "source": [
    "## Complete Uncertainty Budget Summary\n",
    "\n",
    "Now we'll compile all 8 uncertainty sources into a complete uncertainty budget and demonstrate how to combine them properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-budget-calc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE UNCERTAINTY BUDGET\n",
      "==================================================\n",
      "Individual Uncertainty Components:\n",
      "-----------------------------------\n",
      "Repeatability       :     4.80 ppm\n",
      "Reproducibility     :     0.85 ppm\n",
      "Stability           :     3.13 ppm\n",
      "Drift               :     3.10 ppm\n",
      "Resolution          :     0.29 ppm\n",
      "Reference Standard  :     2.10 ppm\n",
      "Ref Std Stability   :     0.20 ppm\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Create uncertainty budget DataFrame\u001b[39;00m\n\u001b[32m     12\u001b[39m budget_data = {\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mSource\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(uncertainty_budget.keys()),\n\u001b[32m     14\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mUncertainty (ppm)\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(uncertainty_budget.values()),\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33mRectangular\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRectangular\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNormal\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNormal\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m budget_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbudget_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Calculate variance contributions\u001b[39;00m\n\u001b[32m     23\u001b[39m variances = [u**\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m uncertainty_budget.values()]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/mechanical-engineering-metrology-and-measurements/.venv/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/mechanical-engineering-metrology-and-measurements/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/mechanical-engineering-metrology-and-measurements/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/mechanical-engineering-metrology-and-measurements/.venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Complete Uncertainty Budget Analysis\n",
    "print(\"COMPLETE UNCERTAINTY BUDGET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Display all uncertainty sources\n",
    "print(\"Individual Uncertainty Components:\")\n",
    "print(\"-\" * 35)\n",
    "for source, value in uncertainty_budget.items():\n",
    "    print(f\"{source:<20}: {value:>8.2f} ppm\")\n",
    "\n",
    "# Create uncertainty budget DataFrame\n",
    "budget_data = {\n",
    "    'Source': list(uncertainty_budget.keys()),\n",
    "    'Uncertainty (ppm)': list(uncertainty_budget.values()),\n",
    "    'Type': ['A', 'A', 'A', 'B', 'B', 'B', 'B', 'A'],  # Type A or B\n",
    "    'Distribution': ['Normal', 'Normal', 'Normal', 'Rectangular', \n",
    "                    'Rectangular', 'Rectangular', 'Normal', 'Normal']\n",
    "}\n",
    "\n",
    "budget_df = pd.DataFrame(budget_data)\n",
    "\n",
    "# Calculate variance contributions\n",
    "variances = [u**2 for u in uncertainty_budget.values()]\n",
    "total_variance = sum(variances)\n",
    "contributions = [(v/total_variance)*100 for v in variances]\n",
    "\n",
    "budget_df['Variance'] = variances\n",
    "budget_df['Contribution (%)'] = contributions\n",
    "\n",
    "print(f\"\\nDetailed Uncertainty Budget:\")\n",
    "print(budget_df.round(2))\n",
    "\n",
    "# Calculate combined standard uncertainty\n",
    "combined_uncertainty = math.sqrt(total_variance)\n",
    "print(f\"\\nCombined Standard Uncertainty: {combined_uncertainty:.2f} ppm\")\n",
    "\n",
    "# Calculate expanded uncertainty (k=2 for 95% confidence)\n",
    "coverage_factor = 2.0\n",
    "expanded_uncertainty = coverage_factor * combined_uncertainty\n",
    "print(f\"Expanded Uncertainty (k=2): {expanded_uncertainty:.2f} ppm\")\n",
    "\n",
    "# Show top contributors\n",
    "top_contributors = budget_df.nlargest(3, 'Contribution (%)')\n",
    "print(f\"\\nTop 3 Contributors:\")\n",
    "for idx, row in top_contributors.iterrows():\n",
    "    print(f\"{row['Source']}: {row['Contribution (%)']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-visualization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of uncertainty budget\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Pie chart of contributions\n",
    "plt.subplot(2, 1, 1)\n",
    "colors = ['lightblue' if t == 'A' else 'lightcoral' for t in budget_df['Type']]\n",
    "plt.pie(budget_df['Contribution (%)'], labels=budget_df['Source'], autopct='%1.1f%%',\n",
    "        colors=colors, startangle=90)\n",
    "plt.title('Uncertainty Budget Contributions\\n(Blue = Type A, Red = Type B)')\n",
    "\n",
    "# Bar chart of uncertainties\n",
    "plt.subplot(2, 1, 2)\n",
    "bars = plt.bar(range(len(budget_df)), budget_df['Uncertainty (ppm)'], color=colors)\n",
    "plt.xlabel('Uncertainty Source')\n",
    "plt.ylabel('Uncertainty (ppm)')\n",
    "plt.title('Individual Uncertainty Components')\n",
    "plt.xticks(range(len(budget_df)), budget_df['Source'], rotation=45, ha='right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add values on bars\n",
    "for bar, value in zip(bars, budget_df['Uncertainty (ppm)']):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "             f'{value:.1f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nSUMMARY STATISTICS:\")\n",
    "print(f\"Total number of uncertainty sources: {len(uncertainty_budget)}\")\n",
    "print(f\"Type A sources: {sum(1 for t in budget_df['Type'] if t == 'A')}\")\n",
    "print(f\"Type B sources: {sum(1 for t in budget_df['Type'] if t == 'B')}\")\n",
    "print(f\"Largest single contributor: {budget_df.loc[budget_df['Contribution (%)'].idxmax(), 'Source']}\")\n",
    "print(f\"({budget_df['Contribution (%)'].max():.1f}% of total variance)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV for documentation\n",
    "budget_df.to_csv('8_sources_uncertainty_budget.csv', index=False)\n",
    "\n",
    "# Create summary report\n",
    "summary_report = {\n",
    "    'Parameter': ['Combined Standard Uncertainty', 'Expanded Uncertainty (k=2)', \n",
    "                 'Relative Uncertainty (%)', 'Dominant Source', 'Number of Sources'],\n",
    "    'Value': [f'{combined_uncertainty:.2f} ppm', f'{expanded_uncertainty:.2f} ppm',\n",
    "             f'{(expanded_uncertainty/nominal_value)*100:.2f}%',\n",
    "             budget_df.loc[budget_df['Contribution (%)'].idxmax(), 'Source'],\n",
    "             len(uncertainty_budget)]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_report)\n",
    "summary_df.to_csv('uncertainty_summary_report.csv', index=False)\n",
    "\n",
    "print(\"Results exported to:\")\n",
    "print(\"• 8_sources_uncertainty_budget.csv\")\n",
    "print(\"• uncertainty_summary_report.csv\")\n",
    "\n",
    "print(f\"\\nFINAL RESULT:\")\n",
    "print(f\"Measurement: {nominal_value:.1f} ± {expanded_uncertainty:.1f} ppm (k=2, ~95% confidence)\")\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"• All 8 essential uncertainty sources have been evaluated\")\n",
    "print(f\"• {budget_df.loc[budget_df['Contribution (%)'].idxmax(), 'Source']} is the dominant contributor\")\n",
    "print(f\"• Type {'A' if budget_df[budget_df['Type']=='A']['Contribution (%)'].sum() > 50 else 'B'} uncertainties dominate\")\n",
    "print(f\"• Focus improvement efforts on the top contributors for maximum impact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-conclusion",
   "metadata": {},
   "source": [
    "## Conclusion and Key Takeaways\n",
    "\n",
    "This notebook has demonstrated the **8 Sources of Uncertainty in Measurement** that should be included in every uncertainty budget according to Rick Hogan's guide:\n",
    "\n",
    "### The 8 Essential Sources:\n",
    "1. **Repeatability** - Random variations under repeatable conditions (Type A)\n",
    "2. **Reproducibility** - Variations when measurement conditions change (Type A) \n",
    "3. **Stability** - How stable the measurement process is over time (Type A)\n",
    "4. **Bias** - Systematic error relative to reference value (Type B)\n",
    "5. **Drift** - Systematic change in measurement error over time (Type B)\n",
    "6. **Resolution** - Smallest detectable change in measurement (Type B)\n",
    "7. **Reference Standard** - Uncertainty from calibration standards (Type B)\n",
    "8. **Reference Standard Stability** - Variability in reference uncertainty (Type A)\n",
    "\n",
    "### Key Learning Points:\n",
    "- These sources typically influence **every measurement** you will make\n",
    "- They are commonly **required by accreditation bodies** like A2LA\n",
    "- Each source has specific **calculation methods** and **definitions**\n",
    "- Understanding **when to include/exclude** certain sources is critical\n",
    "- **Type A** uncertainties are evaluated statistically\n",
    "- **Type B** uncertainties use non-statistical methods\n",
    "- **Combined uncertainty** uses root-sum-of-squares for independent sources\n",
    "- Focus improvement efforts on the **largest contributors** first\n",
    "\n",
    "### Next Steps:\n",
    "1. Apply these calculations to your own measurement processes\n",
    "2. Include all 8 sources in your uncertainty budgets\n",
    "3. Validate your approach with accreditation body requirements\n",
    "4. Regularly update uncertainty evaluations with new calibration data\n",
    "5. Focus improvement efforts on dominant uncertainty contributors\n",
    "\n",
    "**Reference:** *Sources of Uncertainty in Measurement for Every Uncertainty Budget* by Rick Hogan, ISOBudgets LLC (2015)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechanical-engineering-metrology-and-measurements",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
